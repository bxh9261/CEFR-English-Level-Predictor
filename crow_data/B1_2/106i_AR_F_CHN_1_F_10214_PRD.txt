P5D2 Argumentative Essay Assignment 
April 15, 2015 
Just Tools and Unpredictable future 
Did you remember the lovely robots called Tars, Case and Kipp in the new sci-fi movie _Interstellar_? In the movie, they are Copper's friends and help him to travel successfully. Will it be possible to have such robot friends in the future? Or they will just appear in novels or movies? These robots are Artificial Intelligence robots. For my research in this semester, I tried to find the relationship between AI and humans in the future. Among the papers I read, I found many people, including professors in this area, were worrying about AI may lead humans in the future. Then I interviewed a professor at Purdue about this topic. His answers gave me a clearer view and sight of the future of Artificial Intelligence as well as the relationship. Now humans are using AI as tools. This kind of relationship will still last for at least fifty years. If we arrive the "singularity", which will be explained later, the relationship between humans and AIs will be unpredictable. So, it's too early to worry about AI and AI will more possibly not be enemies to humans. 
If AI can lead humans, first they must be human-level, which means they can think by themselves. However, the facts showed AI machines still need a long time to approach human-level. Turing test is a test which was invented by Alan Turing, the greatest expert in Computer Science. It is used for testing whether a machine has human intelligence. In the test, AI machines need to make humans think they are real people instead of robots by talking with real people. On June 7, 2014, at a contest marking the 60th anniversary of Alan Turing's death, a chatterbot called Eugene Goostman made 33% of the judges thought it was human. Later the organizer of this event, Kevin Warwick, considered it had passed the Turing test. Though the experts considered Eugene had passed the test, the rate was only 33%. The fact is, most people can distinguish AI and humans well and AI can just do very simple reasoning with the help of humans. Human-level AI is still far away from us. 
How long will it take to make a human-level AI? Is it too early to worry about AI? In the Cambridge, Cabs and Copenhagen: My Route to Existential Risk Huw Price,2013 from the New York Times, Huw Price talked about the concept of "singularity". The singularity is "the hypothesis that accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control". Scholars believe that after "singularity", AI will achieve the human-level. So the question becomes - when "singularity" will come? The answer is no one can predict it. In the interview, Prof. Jeffrey, who is a professor at Purdue now teaching the lessons related to AI, gave me an example to explain this answer. Like people who could not predict when the Second Industrial Revolution would happen in 1850s, we cannot predict the "singularity" as well. Moreover, it's impossible to prevent it from happening. If Edison did not invent the electric lamp, would it mean no one else could invent the lamp and the Second Industrial Revolution would not happen? Of course not. The same to Artificial Intelligence. We are sure that the "singularity" will come someday, but no one knows how and when. What we now know is, AI still needs a lot of achievements and there is no indication that the "singularity" will come in next 50 years. It means that it's too early to worry about it. 
If we think about the future very far away, when we achieve the "singularity", will it mean that AI and humans will become enemies? Can we get along with each other just like Case gets along with Copper in _Interstellar_? Researches in biology show that our thoughts and emotions are related to "electroencephalogram" in the brain. Now scholars are trying to find ways to control that, which means we may be able to control thoughts and emotions someday. So we may be able to control what AI will think in the future. If this can be realized, AI and humans can help each other in many ways. Though now there is no evidence that we can control emotions and thoughts someday, it is still a possible way to try to prevent AI from being harmful. 
However, on the other side, the scholars who are worrying about AI established the Center for the Study of Existential Risk in Is Artificial Intelligence a Threat? Angela Chen, 2014 from The Chronicle of Higher Education. However, what they forget is, until now, AI still does not have breakthroughs. GPS still makes mistakes very often. Siri just can answer very easy questions. All these machines in our life are harmless. Just like How artificial intelligence is changing our lives Gregory M. Lamb, 2012 comes from The Christian Science Monitor says, they are just tools which make our life much easier and more convenient now. Based on the conclusion before, this kind of relationship will last for a long time-until the singularity comes. 
Artificial Intelligence is an amazing area and make all of us think about future life. But worrying about its danger is not necessary now. Since AI needs a long period of time to achieve human-level, we should not focus on it too much. All the evidence, not only the results of Turing Test, but the time when the "singularity" may happen, prove that AI will still be our tools for a long time. On the other side, if we think about the future hundreds of years later, the fact is we cannot prevent the "singularity" from happening in someday. Now scholars are trying to do best to prevent the danger. So, as I mentioned in the first paragraph, it's too early to think about the relationship of AI and humans and the more possible answer is that AI will still be our friends. 
