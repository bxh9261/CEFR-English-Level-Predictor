Argumentative Paper, Draft 3 
04/22/2016 
Artificial Intelligence: how close are we to our future as slaves or as master of robots? 
Introduction 
	Artificial Intelligence (AI) is the term given to extremely smart machines/ computers that can perform multiple tasks as quickly as possible. The goal of anyone involved in this area of science is to make machines faster and better, to reach (or even surpast) the intelligence level of the human brain so that they can be used to solve complex problems. Since the first ever computers created by Charles Babbage in the 1800's and Alan Turing during the Second World War , computers/AI have advanced significantly and there is research being done in this area by major companies and universities (Russell, S. & Norvig, P, 1995, pages 15-16). Due to the complexity of AI, there are thousands of parts that AI is broken down to and researched. While thinking about AI, several unanswered questions come to mind, some of which include - how far away is that point of time when true AI is created and when that point comes, will it be a threat to us? Or will there be peaceful coexistence? These two questions have been the prime interest of my research which hopes to provide enough information to answer them. 
	When talking about technological advancements and achieving true AI many people have different opinions. I believe that we are not really close to real Artificial intelligence; it is still a long way ahead. Considering current progress in AI, it is far less powerful than the human brain, maybe even by several magnitudes; hence it is reasonable to say that it will be a while till we get to a point where we have robots/machine that can replace humans in basic tasks. Talking about true AI being a threat to humanity, I believe that there is no such thing, which is contrary to popular belief due to stories people hear about AI from books and movies. A machine is designed/programmed to do (a) task(s) and will do nothing more. 
Main Body 
	When it comes to finding out when will true Artificial intelligence be achieved, it is important to consider the factors that greatly contribute to it, such as technology progress, designing of faster and faster computers etc. According to Dr. Bob Givan, a professor in the School of Electrical and Computer Engineering who is currently involved in research in AI and has been in this field for some time, true AI is still a long way (personal communication, March 22,2016). He also added that since technological advancements in human civilization has always accelerated and at this time programmers have done wonders with computers that haven't even been around for a decade, it is impossible to completely know when true AI will be invented. But one thing for sure is that no matter what, technology advanced enough to have machines as complex as human brains is still a long time away, maybe even centuries (Kurzweil, R 2006). 
	To understand the situation, Dr. Givan spoke about the Alpha Go. It is a program designed by Google Inc. that plays the game Go (similar to chess). Recently, it defeated the world champion at the game of Go. The intriguing fact was that program was not written with the strategy to win the game, but designed to learn the game itself and it did achieve its goal of beating the game. The prediction made that it would take five to ten years to beat the game was proved wrong. This is the prime example that shows us exactly how unpredictable technology advancement and civilization is and hence is predicting the future true AI. 
	It is a common opinion that when true artificial intelligence is invented, the ability to make decisions and act accordingly of the machine could be a threat to humanity. This is because it is believed that if a machine becomes orders of magnitude more intelligent than humans, it might be hard to predict or control its action (Barrat, J. 2013). But the problem isn't the inevitable outcome; it is how to make sure this problem doesn't arrive. According to Dr. Givan, programming the goals of an intelligent program to match the desired output over a wide range of unknown future situations is almost impossible. Any mismatch between the goals input and the actual output may be hard to fix and may have drastic results (personal communication, March 22,2016). To understand better, think of an intelligent machine programmed to solve the Riemann hypothesis (an unsolved mathematic hypothesis), it can create sub goals to say transform the earth to programmable matter for calculations. The machine would then resist any attempts to stop or prevent any of the sub goals (Bostrom N., 2014) which is what is referred to as the threat. We should not be fearing an independent and intelligent machine to do something unexpected but we should be looking at ways to prevent unwanted situations from all the possible outcomes. 
Conclusion 
	When thinking about intelligent machines today, which consist of computers, mobile phones, AI in these devices like google now and siri etc. the question related to the future of AI comes to mind. When will machines that can think like humans be created? and if ever created will they harm us is anyway? Technology is advancing at an exponential rate so it is hard know exactly how close we are to that point. But due to the fact that machines now slower than the human brain by several magnitudes, it is reasonable to say that it is not anywhere in the near future. The unexpected achievement regarding the Alpha Go is a clear example of the spontaneous nature of technology development. As far as the danger from machines is concerned, a machine will never do anything it is not programmed to unless it creates a sub goal, hence the real issue is to design codes that make sure that any unfavorable outcome does not occur. Hence AI not something we should consider a threat. Since AI is the future of technology, we must take steps to make it is safe and beneficial to us. 
Refrences 
Russell, S. & Norvig, P.(1995). A modern approach. Artificial Intelligence. Prentice-Hall, Egnlewood Cliffs, 25, 27. 
Kurzweil, R. (2006). The singularity is near: When humans transcend biology. New York: Penguin Books. 
Barrat, J. (2013). Our final invention: Artificial intelligence and the end of the human era. 
Bostrom, N. (2014). Superintelligence: Paths, Dangers. Strategies, 30-36. 
Dear Reader, 
	In this final draft of the Argumentative paper I wrote about Artificial intelligence, how close are we to it, and will it be a threat to us. In this paper I wrote about my positions on the two arguments and tried to provide support for both. One challenge I faced while writing this paper was to find the best way to organize the content. I believe the weakest part of this paper is its introduction and conclusion, more information can be added to make it better 
	If I had more time to write this draft, I would organize the writing even more for a more quality paper. I would also conduct more research to get a better insight on the problem and come up with better answers. 
Sincerely, 
