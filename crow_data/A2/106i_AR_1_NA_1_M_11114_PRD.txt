Argumentative Essay First Draft 
March 29, 2016 
Argumentative Essay 
In the past two decades, artificial intelligence (AI) is moving very fast that it sometimes even seems "magical." As we enjoy the convenience AI has brought to us life, some people started to think about that AI would threaten human existence like in the science-fiction "future" - the stuff of "The Terminator" and "The Matrix". But in fact, the current AI technologies are still way far from have some kinds of human level AI robots, not even nearly close to any sort of super intelligence that will take over the world. The concerns towards AI technologies is invalid. 
In the interview with Mr. Wei Zhao, an expert in machine learning in AI at Wicresoft. He introduced me about one of the most advanced AI technologies called Deep Learning which is a technic that used on AI to make it master skill by learning itself instead of programing. By using the Deep Learning, machines sometimes can surpass human in some fields. In March 2016, an AI Go player, Alpha Go, beat the human Go game world champion Shishi Li with score of 4 to 1. It's incredible how well an AI machine can do in Go game, but it is not meaning that the AI machine is better than human. It may good at one thing, but other things that any human can do like walk, communicate, and fight, it probably doesn't have any clue with them. As what Wei mentioned, Deep Learning is single learning object limited, which means that Deep Learning is unable to generalize and learn other information. The kind of super intelligence is still too far from us. 
	Some people would say that even Stephen Hawking, Elon Musk, and Bill Gates warned about the danger of AI, their words have to mean some things and also AI would not be a threat to us with current technology doesn't mean the "Terminator" can't come true in the future. So firstly, they did warn about AI, but if we look closely to what Stephen Hawking wrote, there is a precondition towards threat of AI. "Unfortunately, it (AI) would be the last (biggest event in human history) unless we learn how to avoid the risks." Yes, AI could be a big problem unless we can't not control it. And on January 13, 2015, the AI community has signed a letter calling for make AI that helps, rather than destroys, humanity. (Clark) It means that AI research companies had agreed that AI technologies would only be societal benefits in the future, so with the agreement, the "Terminator" would only exist in the movies. 
	One thing AI do will affect human society is that, in the future AI will "battle" resources from us. What that mean is that AI robots will replace many of the positions that easy for them like manufacturing, and that will cause some people lose their jobs. But it is only a superficial phenomenon. With the pressure of AI might resources from us, most people will work harder to build more value of themselves, and in the future, it would be more likely that AI machines would do the basic and easy works for us, and with their assist, everyone can play out more value of himself or herself. In Artificial Intelligence, author Norvig stated a human-machine partnership. He predicted the relationship between human and artificial intelligence as a partnership of human and tool. "The 'tool' will get ever better as they become more intelligent, and we will become better as well." he predicted. (Norvig, 2012) 
	Indeed, the AI technologies are moving so fast that things like self-driving car, personal voice assistant we ever all come true. With the advanced technologies, we should more think about how to use it and make it more advance instead of being scared of it. 
Reference 
PR Newswire (Apr 2015) The 'Uncrossable' Robot Artificial Intelligence Line. Retrieved from: http://search.proquest.com.ezproxy.lib.purdue.edu/docview/1673071416?rfr_id=info%3Axri%2Fsid%3Aprimo 
Norvig, Peter (2012). Artificial Intelligence. Retrieved from: http://web.b.ebscohost.com.ezproxy.lib.purdue.edu/ehost/detail/detail?vid=1&sid=4aa3f913-c791-42dc-b262-44c82024dca8%40sessionmgr110&hid=115&bdata=Jn Npd GU9ZWhvc3Qtb Gl2ZQ%3d%3d#AN=83053728&db=aph 
Aron, Jacob (2012). Games that Know You. Retrieved from: http://web.b.ebscohost.com.ezproxy.lib.purdue.edu/ehost/detail/detail?vid=1&sid=f142304a-8f8b-437c-9d52-898de6ad1549%40sessionmgr115&hid=115&bdata=Jn Npd GU9ZWhvc3Qtb Gl2ZQ%3d%3d#AN=76451211&db=aph 
Clark, Liat (Jan 13, 2015) Deep Mind and Stephen Hawking sign letter urging AI oversight. Retrieved from: http://www.wired.co.uk/news/archive/2015-01/13/avoiding-the-inevitable-robot-uprising 
Sainato Michael (08/19/15) Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence. Retrived from: http://observer.com/2015/08/stephen-hawking-elon-musk-and-bill-gates-warn-about-artificial-intelligence/ 
Marcus. Gary (Oct 24, 2013) Why We Should Think About The Threat Of Artificial Intelligence. Retrived from: http://www.newyorker.com/tech/elements/why-we-should-think-about-the-threat-of-artificial-intelligence 
