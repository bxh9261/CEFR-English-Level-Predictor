Argumentative Essay Final Draft 
April 3rd, 2016 
"Danger" of Artificial Intelligence 
In the past two decades, artificial intelligence (AI) is moving very fast that it sometimes even seems magical. Things like self-driving car, personal voice assistant, and all kinds of robots that we ever dreamed of all come true. As we enjoy the convenience AI has brought to us life, some people started to think that AI would threaten human existence like in the science-fiction "future" - "The Terminator" and "The Matrix". In fact, the current AI technologies are still way far from have some kinds of human level AI robots, not even nearly close to any sort of super intelligence that will take over the world. AI robots will threaten existence of humanity is only in our imaginations. 
Not only limited to learn existed human knowledges, AI machines are usually master of only one skill. Wei, an expert in AI at Wicrosoft, mentioned in the interview that Deep Learning is single learning object limited, which means that machines are unable to generalize and learn any information other than their original tasks. 
Compare human to machines, every normal person can draw upon their experiences to make an analyzation in every new situation, and try different ways to find an efficient to move on, but no machines are able to do these. So there is no way for a machine that is only capable of doing what we known and also not capable of doing everything we can to endanger us. 
	Some people would say that even Stephen Hawking, Elon Musk, and Bill Gates warned about the threat of AI, so they believe their words have to mean some things. And they speculate that AI would not be a threat to us with current technology doesn't mean the "Terminator" can't come true in the future. It is undeniably that Stephen Hawking, Elon Musk, and Bill Gates did warn about AI; however, if we look closely to what Stephen Hawking wrote, there is a precondition towards threat of AI. "Success in creating AI would be the biggest event in human history." Wrote by Stephen Hawking in Independent 201. "Unfortunately, it might also be the last unless we learn how to avoid the risks." (Hawking, 2014) So yes, AI could be a big problem unless we can't not control it, but AI machines are built based on what we have known, there should not be a problem of controlling for the things we made ourselves. Also on January 13, 2015, the AI community has signed a letter calling for make AI that helps, rather than destroys, humanity (Clark, 2015). Will a robot only be capable of creating do anything to threaten human society? Absolutely not. It may influence our society, but it won't become a threat. 
One thing AI does will affect human society is that, in the future AI will "battle" some job positions with us. (Marcus, 2013) AI robots are more efficient than human while doing some basic things like manufacturing, so when robots replace these positions, many will people lose their jobs. But as robots replace people, there probably will be coming up some new position like robot and machine supervisor that require high skill. So AI give a change for people who get replaced by robot work harder to become the robot supervisor, it's more likely that AI lift them up. 
The relationship between human and machine is partnership that is like the partnership between human and tool. "The 'tool' will get ever better as they become more intelligent, and we will become better as well." (Norvig, 2012) Instead of being afraid of AI, we need to learn to better use and control it. In my opinion, AI is like an injection of fresh blood to our world, and it will bring a better tomorrow! 
